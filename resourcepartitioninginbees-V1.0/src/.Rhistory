subSeq=list(seq[[i]][k:(k+subSeqSize-1)]);
matchedSubseq=match(listDistinctSubseq,subSeq);
if (sum(matchedSubseq,na.rm=TRUE)==0)
{
listDistinctSubseq=c(listDistinctSubseq,subSeq);
distinctSubseqInCommon=c(distinctSubseqInCommon,FALSE);
}else{
indexMatchedSubseq=which(!is.na(matchedSubseq));
distinctSubseqInCommon[indexMatchedSubseq]=TRUE}
}
};
visitationsInCommon=list(rep(FALSE,l1),rep(FALSE,l2));
for (i in (1:2))
{
for (k in (1:nSubseq[i]))
{
subSeq=list(seq[[i]][k:(k+subSeqSize-1)]);
indexMatchedSubseq=which(!is.na(match(listDistinctSubseq,subSeq)));
if (distinctSubseqInCommon[indexMatchedSubseq])
{
visitationsInCommon[[i]][k:(k+subSeqSize-1)]=TRUE
}
}
};
sab=sum(visitationsInCommon[[1]])+sum(visitationsInCommon[[2]]);
return(sab/(2*max(l1,l2)))
}
}
SubSequenceSimilarity(seq1,seq2,subSeqSize)
subSeqSize=3
seq1=c(5,3,4)
seq2=c(5, 3, 4, 2, 5, 3, 4)
SubSequenceSimilarity=function(seq1,seq2,subSeqSize)
{
l1=length(seq1);
l2=length(seq2);
if (l1<subSeqSize | l2<subSeqSize)
{return(0)} else {
listDistinctSubseq=list();
distinctSubseqInCommon=c()
nSubseq1=l1-subSeqSize+1;
nSubseq2=l2-subSeqSize+1;
seq=c(list(seq1),list(seq2));
nSubseq=c(nSubseq1,nSubseq2);
for (i in (1:2))
{
for (k in (1:nSubseq[i]))
{
subSeq=list(seq[[i]][k:(k+subSeqSize-1)]);
matchedSubseq=match(listDistinctSubseq,subSeq);
if (sum(matchedSubseq,na.rm=TRUE)==0)
{
listDistinctSubseq=c(listDistinctSubseq,subSeq);
distinctSubseqInCommon=c(distinctSubseqInCommon,FALSE);
}else{
indexMatchedSubseq=which(!is.na(matchedSubseq));
distinctSubseqInCommon[indexMatchedSubseq]=TRUE}
}
};
visitationsInCommon=list(rep(FALSE,l1),rep(FALSE,l2));
for (i in (1:2))
{
for (k in (1:nSubseq[i]))
{
subSeq=list(seq[[i]][k:(k+subSeqSize-1)]);
indexMatchedSubseq=which(!is.na(match(listDistinctSubseq,subSeq)));
if (distinctSubseqInCommon[indexMatchedSubseq])
{
visitationsInCommon[[i]][k:(k+subSeqSize-1)]=TRUE
}
}
};
sab=sum(visitationsInCommon[[1]])+sum(visitationsInCommon[[2]]);
return(sab/(2*max(l1,l2)))
}
}
SubSequenceSimilarity(seq1,seq2,subSeqSize)
library(plyr) # count
library(rstudioapi) # getActiveDocumentContext
library(RColorBrewer) # colorRampPalette
library(bipartite) # H2fun, DIRT_LPA_wb_plus
library(beepr) # beep
library(MASS) # ?
library(Rcpp) # sourceCpp
library(lme4) # glmer
library(emmeans) # lstrends
library(ggplot2)
library(ggthemes)
library(gtable)
library(grid)
library(gridExtra)
library(tibble)
library(car)
library(ggpubr)
rm(list=ls());
currentPath = getActiveDocumentContext()$path
setwd(dirname(currentPath))
# Functions & Sourcing ----------------------------------------------------
SinkGLMEROutput = function(name,testOutput,path,hoc=NULL)
{
file.create(paste(path,"/",name,".txt",sep=""))
sink(paste(path,"/",name,".txt",sep=""))
print(summary(testOutput))
cat("\n\n")
print(anova(testOutput))
cat("\n\n")
if(!is.null(hoc)) print(hoc);
sink(NULL)
}
source("01-Functions.R")
# Parameters --------------------------------------------------------------
# Specify the folder & path associated. getwd() returns already the path until the root. Only specify the path from the root.
simulationToAnalyse = "/Output";
# Simulation specifications
numberOfArrays = 1;
numberOfSimulations = 500;
numberOfBouts = 40;
numberOfBees = 1;
# numberOfResources = 10;
arrayOfTest = c("plos")
overwriteFiles = TRUE;
makeFilm = FALSE; # Create a 2D density plot for each array and all arrays combined
# SubSeqSimilarity specific parameters
iter = 100;
subSeqSize = 3;
stopAfterTrapline = F;
# Root Code (Run before any part) -----------------------------------------
# Get to the specified path and retrieve the file in this folder.
outputDirectory = paste(getwd(),simulationToAnalyse,sep="");
testFolders = list.files(path=outputDirectory);
# By default we retrieve files that contain the "generate" word.
testFolders = testFolders[CharacterMatch(testFolders,"plos")];
if (length(testFolders)==0) {testFolders=c("")}
numberOfTests = length(testFolders);
# Initialize output dataframe
arrayTypesOnData = c();
learningFactors = c();
abandonFactors = c();
routeCompares = c();
for(fld in testFolders)
{
if (fld=="") {
arrayInfos = read.csv(paste(outputDirectory,"/",fld,"Array01/arrayInfos.csv",sep=""))
beeInfos = read.csv(paste(outputDirectory,"/",fld,"Array01/beeInfos.csv",sep=""))
learningFactors = c(learningFactors,beeInfos$learningFactor[1]);
abandonFactors = c(abandonFactors,beeInfos$abandonFactor[1]);
if(beeInfos$routeCompare[1]) routeCompares = c(routeCompares,"routeCompare") else routeCompares = c(routeCompares,"noRouteCompare");
arrayNameChr = paste("R",arrayInfos$numberOfResources,"-P",arrayInfos$numberOfPatches,sep="")
if(!is.na(arrayInfos$flowerPerPatch)) {arrayNameChr = paste(arrayNameChr,"-",arrayInfos$flowerPerPatch,sep="")}
arrayTypesOnData = c(arrayTypesOnData,arrayNameChr)
}else{
arrayInfos = read.csv(paste(outputDirectory,"/",fld,"/Array01/arrayInfos.csv",sep=""))
beeInfos = read.csv(paste(outputDirectory,"/",fld,"/Array01/beeInfos.csv",sep=""))
learningFactors = c(learningFactors,beeInfos$learningFactor[1]);
abandonFactors = c(abandonFactors,beeInfos$abandonFactor[1]);
if(beeInfos$routeCompare[1]) routeCompares = c(routeCompares,"routeCompare") else routeCompares = c(routeCompares,"noRouteCompare");
arrayNameChr = paste("R",arrayInfos$numberOfResources,"-P",arrayInfos$numberOfPatches,sep="")
if(!is.na(arrayInfos$flowerPerPatch)) {arrayNameChr = paste(arrayNameChr,"-",arrayInfos$flowerPerPatch,sep="")}
arrayTypesOnData = c(arrayTypesOnData,arrayNameChr)}
}
numberOfArrayTypes = length(arrayTypesOnData)
outputData = data.frame(arrayType = rep(arrayTypesOnData,each=(numberOfTests/numberOfArrayTypes)*numberOfArrays*numberOfSimulations*numberOfBouts*numberOfBees),
algorithm = rep(routeCompares,each=numberOfArrays*numberOfSimulations*numberOfBouts*numberOfBees),
learningValue = rep(learningFactors,each=numberOfArrays*numberOfSimulations*numberOfBouts*numberOfBees),
abandonValue = rep(abandonFactors,each=numberOfArrays*numberOfSimulations*numberOfBouts*numberOfBees),
arrayNumber = rep(c(1:numberOfArrays),each=numberOfSimulations*numberOfBouts*numberOfBees,times=numberOfTests),
simulation = rep(c(1:numberOfSimulations),each=numberOfBouts*numberOfBees,times=numberOfTests*numberOfArrays),
bout = rep(c(1:numberOfBouts),each=numberOfBees,times=numberOfTests*numberOfArrays*numberOfSimulations),
bee = rep(c(1:numberOfBees),times=numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts),
stringsAsFactors = F);
for(testNumber in 1:length(testFolders))
{
testFolderName = testFolders[testNumber];
testFolderPath = paste(outputDirectory,"/",testFolderName,sep="");
}
testFolderName
##################### route quality data #############################
# Join the files
rawQualityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts);
relativeQualityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts);
lineRouteQuality = 1;
for(testNumber in 1:length(testFolders))
{
folderName = testFolders[testNumber];
fileDirectory = paste(outputDirectory,"/",folderName,sep="");
## Import route Quality
routeQuality = read.csv(paste(fileDirectory,"/routeQualityDF.csv",sep=""));
extractRawQuality = routeQuality$rawQuality;
extractRelativeQuality = routeQuality$relativeQuality;
dataLength = length(extractRawQuality);
rawQualityVector[c(lineRouteQuality:(lineRouteQuality+dataLength-1))] = extractRawQuality;
relativeQualityVector[c(lineRouteQuality:(lineRouteQuality+dataLength-1))] = extractRelativeQuality;
lineRouteQuality = lineRouteQuality + dataLength;
}
### Output routeQuality
routeQualityData = cbind(outputData[which(outputData$bee==1),],
rawQuality = rawQualityVector,
relativeQuality = relativeQualityVector);
write.csv(routeQualityData,paste(outputDirectory,"/routeQualityData.csv",sep=""),row.names = F)
# Join the files
rawQualityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts);
relativeQualityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts);
lineRouteQuality = 1;
for(testNumber in 1:length(testFolders))
{
folderName = testFolders[testNumber];
fileDirectory = paste(outputDirectory,"/",folderName,sep="");
## Import route Quality
routeQuality = read.csv(paste(fileDirectory,"Array01/routeQualityDF.csv",sep=""));
extractRawQuality = routeQuality$rawQuality;
extractRelativeQuality = routeQuality$relativeQuality;
dataLength = length(extractRawQuality);
rawQualityVector[c(lineRouteQuality:(lineRouteQuality+dataLength-1))] = extractRawQuality;
relativeQualityVector[c(lineRouteQuality:(lineRouteQuality+dataLength-1))] = extractRelativeQuality;
lineRouteQuality = lineRouteQuality + dataLength;
}
### Output routeQuality
routeQualityData = cbind(outputData[which(outputData$bee==1),],
rawQuality = rawQualityVector,
relativeQuality = relativeQualityVector);
write.csv(routeQualityData,paste(outputDirectory,"/routeQualityData.csv",sep=""),row.names = F)
##################### route quality data #############################
# Join the files
rawQualityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts);
relativeQualityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts);
lineRouteQuality = 1;
for(testNumber in 1:length(testFolders))
{
folderName = testFolders[testNumber];
fileDirectory = paste(outputDirectory,"/",folderName,sep="");
## Import route Quality
routeQuality = read.csv(paste(fileDirectory,"/Array01/routeQualityDF.csv",sep=""));
extractRawQuality = routeQuality$rawQuality;
extractRelativeQuality = routeQuality$relativeQuality;
dataLength = length(extractRawQuality);
rawQualityVector[c(lineRouteQuality:(lineRouteQuality+dataLength-1))] = extractRawQuality;
relativeQualityVector[c(lineRouteQuality:(lineRouteQuality+dataLength-1))] = extractRelativeQuality;
lineRouteQuality = lineRouteQuality + dataLength;
}
### Output routeQuality
routeQualityData = cbind(outputData[which(outputData$bee==1),],
rawQuality = rawQualityVector,
relativeQuality = relativeQualityVector);
write.csv(routeQualityData,paste(outputDirectory,"/routeQualityData.csv",sep=""),row.names = F)
#routeQuality
data=read.csv(paste(outputDirectory,"/routeQualityData.csv",sep=""))
modelVector=rep('None',nrow(data))
modelVector[data$learningValue==1.5 & data$abandonValue==1.]="model 1"
modelVector[data$learningValue==1. & data$abandonValue==0.75]="model 2"
modelVector[data$learningValue==1.5 & data$abandonValue==0.75]="model 3"
data["model"]=modelVector
nArrayTypes=length(levels(as.factor(data$arrayType)))
data=aggregate(data,list(data$model,data$bout),mean)
colnames(data)[2]="Model"
ggplot(data = data,aes(x=bout, y=relativeQuality,color=Model)) +
geom_line()+
facet_wrap(~Group.1)
head(data)
#routeQuality
data=read.csv(paste(outputDirectory,"/routeQualityData.csv",sep=""))
modelVector=rep('None',nrow(data))
modelVector[data$learningValue==1.5 & data$abandonValue==1.]="model 1"
modelVector[data$learningValue==1. & data$abandonValue==0.75]="model 2"
modelVector[data$learningValue==1.5 & data$abandonValue==0.75]="model 3"
data["model"]=modelVector
nArrayTypes=length(levels(as.factor(data$arrayType)))
data=aggregate(data,list(data$model,data$bout),mean)
colnames(data)[2]="Model"
ggplot(data = data,aes(x=bout, y=relativeQuality)) +
geom_line()+
facet_wrap(~Group.1)
data=read.csv(paste(outputDirectory,"/routeQualityData.csv",sep=""))
modelVector=rep('None',nrow(data))
modelVector[data$learningValue==1.5 & data$abandonValue==1.]="model 1"
modelVector[data$learningValue==1. & data$abandonValue==0.75]="model 2"
modelVector[data$learningValue==1.5 & data$abandonValue==0.75]="model 3"
data["model"]=modelVector
nArrayTypes=length(levels(as.factor(data$arrayType)))
data=aggregate(data,list(data$model,data$bout),mean)
colnames(data)[2]="Model"
ggplot(data = data,aes(x=bout, y=relativeQuality)) +
geom_line()+
facet_wrap(~Group.1)+
ylim(0,1)
############### similarity data ###################
#/!\ careful: can be quite heavy to run
#function to compute subsequence similarity
SubSequenceSimilarity=function(seq1,seq2,subSeqSize)
{
l1=length(seq1);
l2=length(seq2);
if (l1<subSeqSize | l2<subSeqSize)
{return(0)} else {
listDistinctSubseq=list();
distinctSubseqInCommon=c()
nSubseq1=l1-subSeqSize+1;
nSubseq2=l2-subSeqSize+1;
seq=c(list(seq1),list(seq2));
nSubseq=c(nSubseq1,nSubseq2);
for (i in (1:2))
{
for (k in (1:nSubseq[i]))
{
subSeq=list(seq[[i]][k:(k+subSeqSize-1)]);
matchedSubseq=match(listDistinctSubseq,subSeq);
if (sum(matchedSubseq,na.rm=TRUE)==0)
{
listDistinctSubseq=c(listDistinctSubseq,subSeq);
distinctSubseqInCommon=c(distinctSubseqInCommon,FALSE);
}else{
indexMatchedSubseq=which(!is.na(matchedSubseq));
distinctSubseqInCommon[indexMatchedSubseq]=TRUE}
}
};
visitationsInCommon=list(rep(FALSE,l1),rep(FALSE,l2));
for (i in (1:2))
{
for (k in (1:nSubseq[i]))
{
subSeq=list(seq[[i]][k:(k+subSeqSize-1)]);
indexMatchedSubseq=which(!is.na(match(listDistinctSubseq,subSeq)));
if (distinctSubseqInCommon[indexMatchedSubseq])
{
visitationsInCommon[[i]][k:(k+subSeqSize-1)]=TRUE
}
}
};
sab=sum(visitationsInCommon[[1]])+sum(visitationsInCommon[[2]]);
return(sab/(2*max(l1,l2)))
}
}
#now computing the dataframe
# Assuming at all time a 95% confidence interval
lowerThreshold = iter*0.025;
upperThreshold = iter*0.975;
for(testNumber in 1:length(testFolders))
{
testFolderName = testFolders[testNumber]; # fileName
testFolderPath = paste(outputDirectory,"/",testFolderName,sep=""); # fileDirectory
# Check if the file already exists
testFiles = list.files(path = testFolderPath);
if(any(testFiles=="similarityData.csv") & !overwriteFiles)
{
cat("Similarity computation for test ",testFolderName," is already done. Proceeding to next test.\n",sep="");
next;
}
cat("Starting similarity assessment for test : ",testFolderName,".\n",sep="");
arrays = list.files(testFolderPath);
arrays = arrays[CharacterMatch(arrays,"Array")];
## Initialize output data
similarityDF = data.frame(arrayNumber = rep(c(1:numberOfArrays),each = numberOfSimulations*(numberOfBouts-1)*numberOfBees),
simulation = rep(1:numberOfSimulations, each = (numberOfBouts-1)*numberOfBees, times = numberOfArrays),
bout = rep(1:(numberOfBouts-1),each=numberOfBees,times = numberOfArrays*numberOfSimulations),
bee = rep(1:numberOfBees,times = numberOfArrays*numberOfSimulations*(numberOfBouts-1)),
similarityIndex = 0,
stringsAsFactors = F);
similarityIndexVector = numeric(numberOfArrays*numberOfSimulations*(numberOfBouts-1)*numberOfBees);
lineToFill = 0;
for(arrayNumber in 1:length(arrays))
{
array = arrays[arrayNumber];
arrayDirectory = paste(testFolderPath,array,sep="/");
visitationSequences = read.csv(paste(arrayDirectory,"/matrixOfVisitationSequences.csv",sep=""));
for(sim in 1:numberOfSimulations)
{
simVisitationSequences = subset(visitationSequences,visitationSequences[,1]==sim);
for(bout in 1:(numberOfBouts-1))
{
boutVisitationSequences = simVisitationSequences[which(simVisitationSequences[,2]==bout | simVisitationSequences[,2]==bout+1),];
for(bee in 1:numberOfBees)
{
indVisitationSequences = subset(boutVisitationSequences,boutVisitationSequences[,3]==bee)[,-c(1:3)];
lineToFill = lineToFill + 1;
seq1 = indVisitationSequences[1,-1];
seq1 = as.numeric(seq1)[which(seq1!=0 & seq1!=1)];
seq2 = indVisitationSequences[2,-1];
seq2 = as.numeric(seq2)[which(seq2!=0 & seq2!=1)];
similarityIndexVector[lineToFill] = SubSequenceSimilarity(seq1,seq2,subSeqSize)
}
}
}
}
## Compile all data in the data.frame
similarityDF$similarityIndex = similarityIndexVector;
write.csv(similarityDF,paste(testFolderPath,"/similarityData.csv",sep=""),row.names = F);
}
# Join the files
similarityVector = numeric(numberOfTests*numberOfArrays*numberOfSimulations*numberOfBouts*numberOfBees);
lineSimilarity = 1;
outputDataSim = data.frame();
for(testNumber in 1:length(testFolders))
{
folderName = testFolders[testNumber];
fileDirectory = paste(outputDirectory,"/",folderName,sep="");
## Import SubSeqSim
subSeqSim = read.csv(paste(fileDirectory,"/similarityData.csv",sep=""));
beeInfos = read.csv(paste(fileDirectory,"/Array01/beeInfos.csv",sep=""))
arrayInfos = read.csv(paste(fileDirectory,"/Array01/arrayInfos.csv",sep=""))
arrayType = paste("R",arrayInfos$numberOfResources,"-P",arrayInfos$numberOfPatches,sep="")
extractSimilarity = subSeqSim$similarityIndex
dataLength = length(extractSimilarity);
similarityVector[c(lineSimilarity:(lineSimilarity+dataLength-1))] = extractSimilarity;
lineSimilarity = lineSimilarity + dataLength;
if(beeInfos$routeCompare[1]) algorithmChr = "routeCompare" else algorithmChr = "noRouteCompare"
reorgData = data.frame(arrayType = arrayType,
algorithm = algorithmChr,
learningValue = beeInfos$learningFactor[1],
abandonValue = beeInfos$abandonFactor[1],
subSeqSim)
outputDataSim = rbind(outputDataSim,reorgData);
}
write.csv(outputDataSim,paste(outputDirectory,"/similarityData.csv",sep=""),row.names = F)
#similarity index
data=read.csv(paste(outputDirectory,"/similarityData.csv",sep=""))
modelVector=rep('None',nrow(data))
modelVector[data$learningValue==1.5 & data$abandonValue==1.]="model 1"
modelVector[data$learningValue==1. & data$abandonValue==0.75]="model 2"
modelVector[data$learningValue==1.5 & data$abandonValue==0.75]="model 3"
data["model"]=modelVector
nArrayTypes=length(levels(as.factor(data$arrayType)))
data=aggregate(data,list(data$model,data$bout),mean)
colnames(data)[2]="Model"
ggplot(data = data,aes(x=bout, y=similarityIndex)) +
geom_line()+
facet_wrap(~Group.1)+
ylim(0,1)
?gamma
?softmax
?SoftMax
?knitr
library(knitr)
?knitr
library(DMwR)
install.packages(DMwR)
install.packages('DMwR')
library(DMwR)
library('DMwR')
?exp
a=c(1,2)
length(a)
exp(a)
sum(exp(a))
sum(exp(3*a))
3*a
exp(3*a)
exp(3*a)/sum(exp(3*a))
sum(exp(3*a)/sum(exp(3*a)))
softmax=function(valuesVector,betaQL){
return(exp(betaQL*valuesVector)/sum(exp(betaQL*valuesVector)))
}
softmax(a,3)
Q=matrix(0,nrow=2,ncol=2)
Q
state=1
action=1
max(Q[action,:])
max(Q[action])
Q[1][1]=11
Q[1,2]=12
Q[2,1]=21
Q[2,2]=22
Q
Q[1,]
max(Q[action,])
ApplyOnlineQLearning=function(QTable,state,action,reward,alphaPos,alphaNeg,gammaQL){
#here, action also corresponds to the next state since completely deterministic environment so max(Q(nextState,b)/b in actions)=max(Q(action,b)/b in actions)
delta=reward+gammaQL*max(QTable[action,])-QTable[state,action];
if (delta>=0) {
QTable[state,action]=QTable[state,action]+alphaPos*delta
}else{
QTable[state,action]=QTable[state,action]+alphaNeg*delta
}
}
Q=matrix(0,nrow=2,ncol=2)
ApplyOnlineQLearning(Q,1,2,1,0.1,0.1,0)
Q
ApplyOnlineQLearning=function(QTable,state,action,reward,alphaPos,alphaNeg,gammaQL){
#here, action also corresponds to the next state since completely deterministic environment so max(Q(nextState,b)/b in actions)=max(Q(action,b)/b in actions)
delta=reward+gammaQL*max(QTable[action,])-QTable[state,action];
if (delta>=0) {
QTable[state,action]=QTable[state,action]+alphaPos*delta
}else{
QTable[state,action]=QTable[state,action]+alphaNeg*delta
}
return(QTable)
}
Q=ApplyOnlineQLearning(Q,1,2,1,0.1,0.1,0)
Q
Q=ApplyOnlineQLearning(Q,1,2,0,0.1,0.1,0)
Q
Q=ApplyOnlineQLearning(Q,1,2,-1,0.1,0.1,0)
Q
SoftMax=function(valuesVector,betaQL){
return(exp(betaQL*valuesVector)/sum(exp(betaQL*valuesVector)))
}
ApplyOnlineQLearning=function(QTable,state,action,reward,alphaPos,alphaNeg,gammaQL){
#bee with Q Table (QTable), is in state (state), does action (action), gets a reward (reward)
#apply Q Learning algorithm: QTable[state,action]=QTable[state,action]+alpha*(reward+gamma*max(Q(nextState,b)/b in actions)-Q[state,action])
#alpha: learning rate, gamma: temporal discount factor
#here, action also corresponds to the next state since completely deterministic environment so max(Q(nextState,b)/b in actions)=max(Q(action,b)/b in actions)
#two RL systems: one that reinforces positively some values (use alphaPos), one that reinforces negatively some values (use alphaNeg)
delta=reward+gammaQL*max(QTable[action,])-QTable[state,action];
if (delta>=0) {
QTable[state,action]=QTable[state,action]+alphaPos*delta
}else{
QTable[state,action]=QTable[state,action]+alphaNeg*delta
}
return(QTable)
}
a=matrix(0,nrow=1,ncol=1)
a
nrow(data.frame(a))
